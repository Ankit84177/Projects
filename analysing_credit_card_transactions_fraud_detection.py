# -*- coding: utf-8 -*-
"""Analysing Credit card Transactions Fraud Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bvjmQLlXx7qnHLIGQQSNjlCoSIu_MNl0

# Import **Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from geopy.distance import geodesic
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import roc_curve, roc_auc_score
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV

"""#  Load the Dataset

"""

df = pd.read_csv("/content/fraudTest.csv")
df.shape

"""# Basic Info & Data **Cleaning**"""

# Basic info
print(df.info())
print(df.isnull().sum())

# Check value distribution
print(df['is_fraud'].value_counts())

df.head()

df.tail()

data_types = df.dtypes
data_types

df.describe()#This code summarizes the statistical properties of all the numeric columns

print(df['is_fraud'].value_counts())

print("Fraud rate: {:.2f}%".format(df['is_fraud'].mean() * 100))

"""# **Outlier**"""

plt.figure(figsize=(10, 4))
sns.boxplot(x=df['amt'], color='orange')
plt.title("Outlier Detection in Transaction Amounts")
plt.xlabel("Transaction Amount")
plt.tight_layout()
plt.show()

"""# Exploratory Data Analysis (EDA)"""

# Plot fraud distribution
sns.countplot(x='is_fraud', data=df)
plt.title('Fraud vs Legitimate Transactions')
plt.show()

"""# The distribution of transaction amounts for both legitimate and fraudulent transactions. The plt.yscale('log') line sets the y-axis to a logarithmic scale, which is useful for visualizing data with a wide range of values, like transaction amounts."""

# Amount distribution
sns.boxplot(x='is_fraud', y='amt', data=df)
plt.yscale('log')
plt.title("Transaction Amount by Class")
plt.show()

# Top 5 fraud categories
print("Top fraud categories:")
print(df[df['is_fraud'] == 1]['category'].value_counts().head())

# Check for missing values in each column
mis_values = df.isnull().sum()
# Filter out columns with no missing values
mis_values = mis_values[mis_values > 0]
mis_values

# Dataset Info
print(df.info())

# Check class distribution
print(df['gender'].value_counts())

# Visualize class distribution
sns.countplot(x='gender', data=df)
plt.title('Class Distribution')
plt.show()

"""# Model Training & Evaluation

Model Evaluation
python
Copy
Edit
**bold text**
"""

plt.figure(figsize=(8,5))
sns.histplot(df['amt'], bins=100, log_scale=True)
plt.title('Transaction Amount Distribution')
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x='is_fraud', y='amt', data=df)
plt.title('Transaction Amount by Fraud Label')
plt.show()

top_merchants = df['merchant'].value_counts().nlargest(10).index
merchant_df = df[df['merchant'].isin(top_merchants)]

plt.figure(figsize=(12,6))
sns.countplot(data=merchant_df, y='merchant', hue='is_fraud')
plt.title('Top 10 Merchants and Fraudulent Transactions')
plt.xlabel('Transaction Count')
plt.ylabel('Merchant')
plt.legend(['Legitimate', 'Fraudulent'])
plt.show()

plt.figure(figsize=(12,6))
sns.countplot(data=df, y='category', order=df['category'].value_counts().index, hue='is_fraud')
plt.title('Transaction Category by Fraud')
plt.xlabel('Transaction Count')
plt.ylabel('Merchant Category')
plt.legend(['Legitimate', 'Fraudulent'])
plt.show()

plt.figure(figsize=(6,4))
sns.countplot(data=df, x='gender', hue='is_fraud')
plt.title('Gender Distribution by Fraud')
plt.xlabel('Gender',)
plt.ylabel('Count')
plt.legend(['Legitimate', 'Fraudulent'])
plt.show()

top_cities = df['city'].value_counts().nlargest(10).index
city_df = df[df['city'].isin(top_cities)]

plt.figure(figsize=(12,6))
sns.countplot(data=city_df, y='city', hue='is_fraud')
plt.title('Top Cities and Fraudulent Transactions')
plt.xlabel('Transaction Count')
plt.ylabel('City')
plt.legend(['Legitimate', 'Fraudulent'])
plt.show()

plt.figure(figsize=(15,6))
sns.countplot(data=df, x='state', order=df['state'].value_counts().index, hue='is_fraud')
plt.title('State-wise Fraud Distribution')
plt.xlabel('State')
plt.ylabel('Count')
plt.xticks(rotation=90)
plt.legend(['Legitimate', 'Fraudulent'])
plt.show()

# Check for missing values in the training dataset
print("\nMissing values in the training dataset:")
print(df.isnull().sum())

# Summary statistics for numeric columns
print("\nSummary statistics for numeric columns in the training dataset:")
print(df.describe())

# Distribution of the target variable ('is_fraud') in the training dataset
plt.figure(figsize=(6, 4))
sns.countplot(x='is_fraud', data=df)
plt.title('Distribution of Fraudulent Transactions (Training Dataset)')
plt.xlabel('Is Fraud (0 = No, 1 = Yes)')
plt.ylabel('Count')
plt.show()

# Select only numeric columns for correlation analysis
numeric_data = df.select_dtypes(include=[np.number])

# Compute the correlation matrix
correlation_matrix = numeric_data.corr()

# Plot the heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap (Numeric Columns Only)')
plt.show()

fraud_cities = df[df['is_fraud'] == 1]['city'].value_counts().head(10)
fraud_cities.plot(kind='barh', title="Top 10 Cities with Fraud", figsize=(8, 5))
plt.xlabel("Fraud Count")
plt.ylabel("City")
plt.show()

"""# **Basic ML Models**
Logistic Regression
"""

# Step 1: Remove rows where 'is_fraud' is NaN
df = df[df['is_fraud'].notna()]

# Step 2: (Optional) Also remove NaNs from selected features if any
df = df.dropna()

# Step 3: Now continue normally
features = ['amt', 'city_pop', 'lat', 'long', 'unix_time', 'merch_lat', 'merch_long']
X = df[features]
y = df['is_fraud']

# Step 4: Train-test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Step 5: Scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Step 7: Evaluate
# Step 6: Now model
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(X_train_scaled, y_train)
y_pred = lr.predict(X_test_scaled)

from sklearn.metrics import classification_report, confusion_matrix
print("Logistic Regression:")
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

from sklearn.preprocessing import StandardScaler
features = ['amt', 'city_pop', 'lat', 'long', 'unix_time', 'merch_lat', 'merch_long']
X = df[features]
y = df['is_fraud']


# Split your data first
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# Now scale it
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, classification_report

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)
y_pred_dt = dt.predict(X_test)

print("Decision Tree:")
print(confusion_matrix(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))

"""# **Advanced ML Models**
## Random Forest




"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

print("Random Forest:")
print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

"""# XGBoost"""

from xgboost import XGBClassifier
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

print("XGBoost:")
print(confusion_matrix(y_test, y_pred_xgb))
print(classification_report(y_test, y_pred_xgb))

"""# **ROC Curve Comparison**"""

from sklearn.metrics import roc_curve, roc_auc_score

models = {
    'Logistic Regression': lr,
    'Decision Tree': dt,
    'Random Forest': rf,
    'XGBoost': xgb
}

plt.figure(figsize=(10,6))

for name, model in models.items():
    if name == 'Logistic Regression':
        probs = model.predict_proba(X_test_scaled)[:,1]
    else:
        probs = model.predict_proba(X_test)[:,1]

    fpr, tpr, _ = roc_curve(y_test, probs)
    auc = roc_auc_score(y_test, probs)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f})')

plt.plot([0,1], [0,1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend()
plt.show()

"""# **Hyperparameter Tuning (Example for Random Forest)**"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5, 10]
}

grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='f1', n_jobs=-1)
grid_rf.fit(X_train, y_train)

print("Best Parameters:", grid_rf.best_params_)
print("Best Estimator:", grid_rf.best_estimator_)