# -*- coding: utf-8 -*-
"""Fake news detection - NLP using NLTK

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PS4qO9Fvlf_rCuQ9rFhsefSqk6lvqnUQ

# **Import Libraries**
"""

import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.util import trigrams
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

from sklearn.preprocessing import LabelEncoder

nltk.download('punkt')
nltk.download('punkt_tab')

"""# **Read Data**"""

fake_data = pd.read_csv("/content/Fake.csv.zip")
true_data = pd.read_csv("/content/True.csv.zip")

fake_data.head()

true_data.head()

fake_data['label'] = 1
true_data['label'] = 0

df = pd.concat([fake_data, true_data], axis=0).reset_index(drop=True)

df.isnull().sum()

df = df[['title', 'text', 'label']]
df.head()

df['combined_text'] = df['title'] + " " + df['text']
df.head()

"""# **Preprocessing**"""

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def preprocess_text(text):

    tokens = nltk.word_tokenize(text.lower())
    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]

    trigrams = list(nltk.trigrams(tokens))

    return ' '.join([' '.join(trigram) for trigram in trigrams])

df['processed_text']=df['combined_text'].apply(preprocess_text)
processed_df = df[['processed_text', 'label']]
processed_df.head()

X = df['processed_text']
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

vectorizer = TfidfVectorizer(max_features=5000)
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

"""# **Training**"""

models = {
    "Naive Bayes": MultinomialNB(),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "SVM": SVC(kernel='linear')
}

model_accuracies = {}

for model_name, model in models.items():
    print(f"\nTraining {model_name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    model_accuracies[model_name] = accuracy
    print(f"{model_name} Accuracy: {accuracy:.4f}")
    print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))
plt.bar(model_accuracies.keys(), model_accuracies.values(), color='skyblue')
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Model Accuracies")
plt.xticks(rotation=45)
plt.show()

from sklearn.ensemble import VotingClassifier

voting_clf = VotingClassifier(
    estimators=[
        ("Logistic Regression", models["Logistic Regression"]),
        ("Naive Bayes", models["Naive Bayes"]),
        ("SVM", models["SVM"]),
        ("Random Forest", models["Random Forest"]),
    ],
    voting="hard"
)

print("\nTraining Voting Classifier...")
voting_clf.fit(X_train, y_train)
voting_pred = voting_clf.predict(X_test)
voting_accuracy = accuracy_score(y_test, voting_pred)

model_accuracies["Voting Classifier"] = voting_accuracy
print(f"Voting Classifier Accuracy: {voting_accuracy:.4f}")
print(classification_report(y_test, voting_pred))

plt.figure(figsize=(10, 5))
plt.bar(model_accuracies.keys(), model_accuracies.values(), color='lightgreen')
plt.xlabel("Models")
plt.ylabel("Accuracy")
plt.title("Model Accuracies Including Voting Classifier")
plt.xticks(rotation=45)
plt.show()

